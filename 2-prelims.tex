\section{Preliminaries}
\label{sec:pre}

One of the well-known proofs of the existence of a normal element for a
finite Galois extension \cite[Theorem 6.13.1]{Lang} suggests a randomized
algorithm for finding such an element. Assume $\K/\F$ is a finite Galois
extension with Galois group $G = \lbrace g_1 , \ldots , g_n \rbrace$. If
$x \in \K$ is a normal element, then clearly

\begin{equation}
  \label{eq:fstrow}
  \sum_{j=1}^n 
  c_j g_j(x)=0, \,\,\, c_j \in \F 
\end{equation} 
implies $(c_1, \ldots ,c_n) = 0$.For each $i \in \lbrace 1, \ldots , n\rbrace$, applying $g_i$ to equation \eqref{eq:fstrow} yields
\begin{equation} \label{eq:otherrow}
 \sum_{j=1}^n 
 c_j g_i g_j(x)=0.
\end{equation}

Using \eqref{eq:fstrow} and \eqref{eq:otherrow}, one can form a linear
system $\mat{M}_G(\alpha)\textbf{v} = \textbf{0}$ where, for $\alpha$ in
$\K$,
\[
  \mat M_G(\alpha) =
  \begin{bmatrix}
    g_1 g_1(\alpha) & g_1 g_2(\alpha) & \cdots & g_1 g_n(\alpha) \\
    g_2 g_1(\alpha) & g_2 g_2(\alpha) & \cdots & g_2 g_n(\alpha) \\
    \vdots		& \vdots	& \vdots & \vdots \\
    g_n g_1(\alpha) & g_n g_2(\alpha) & \cdots & g_n g_n(\alpha) \\
  \end{bmatrix}.
\]
Classical proofs then proceed to show that there exists $\alpha \in \K$
with $\det(\mat M_G(\alpha))\neq 0$.

 
This discussion can be used as the basis of a randomized algorithm for
finding a normal element: choose a random element $\alpha$ in $\K$
until we find one such that $ \mat M_G(\alpha)$. A direct
implementation computes all the entries of the matrix and then use
linear algebra to compute its determinant; using fast matrix
arithmetic, this uses uses $O(n^\omega)$ operations in $\K$, that is
$\tilde{n^{\omega+1})$ operations in $\F$. This is at last cubic in
  $n$.

The main contribution of this paper is to show how to speed up this verification;
 
 Since we are working over characteristic zero, we are able to consider a finite subset
 of $\K \cong \F^n$ such that the probability of failure is $\dfrac{1}{n}$, using 
 Schwartz-Zippel lemma (Proposition \ref{thm:zippel}).
 
 If $\lbrace a_1, \ldots , a_n \rbrace$ is an $\F$-basis for $\K$, then in Equations
   \eqref{eq:fstrow} and \eqref{eq:otherrow}, $x$ can be written as $\sum_{i = 1}^nx_i
    a_i$. Now we can rewrite 
    $$
M_G(x) = M_G(x_1,\ldots,x_n) =  $$
$$
\begin{bmatrix}
\sum_{i = 1}^n g_1 g_1(a_i)x_i & \sum_{i = 1}^n g_1 g_2(a_i)x_i & \cdots & 
\sum_{i = 1}^n g_1 g_n(a_i)x_i \\
\sum_{i = 1}^n g_2 g_1(a_i)x_i & \sum_{i = 1}^n g_2 g_2(a_i)x_i & \cdots & 
\sum_{i = 1}^n g_2 g_n(a_i)x_i \\
\vdots		& \vdots	& \vdots & \vdots \\
\sum_{i = 1}^n g_n g_1(a_i)x_i & \sum_{i = 1}^n g_n g_2(a_i)x_i & \cdots & 
\sum_{i = 1}^n g_n g_n(a_i)x_i \\
\end{bmatrix}    
    $$ 
 The following theorem enables us to talk about probability of success (or failure).
 \begin{proposition}\cite[Proposition 98]{Zippel} \label{thm:zippel}
Let $P \in A[X_1, \ldots, X_n]$ be a polynomial with total degree $D$ over an integral domain $A$. Let $S$ be a subset of $A$ of cardinality $B$. Then $$Pr(P(x_1, \ldots , x_n)=0:x_i \in S) \leq \dfrac{D}{B}.$$
\end{proposition}

Now $\det(M_G(x)) \in \K[x_1, \ldots , x_n]$ is a polynomial of total degree $n$ and $\K$ is a field. If $char(\K) =0$, then by considering $S \subset \F \subset \K$ where $|S| = n^2$ and applying the above proposition we get $$Pr(\det(M_G(r_1,\ldots , r_n)) = 0 : r_i \in S)\leq \dfrac{n}{n^2}= \dfrac{1}{n}.$$
 
Now let us take a look at steps 2 and 3 in Algorithm \ref{alg:naive}. Since in the cyclic case $M_G(\alpha)$ is circulant,
 in \cite{Giesbrecht} instead of writing the matrix, the invertibility test is done by means of finding the gcd of an 
 associated polynomial 
$$P(x) = \sum_{i = 1}^n g_ig_1(\alpha)x^{i-1}$$ 
 to $M_G(\alpha)$ and $x^n-1$. Note that in this case the group ring of $G$ over $\K$, $\K[G]$ is isomorphic to $\K[x]/(x^n-1)$,
 $P(x)$ is the isomorphic copy of the orbit sum of $\alpha$ over $\K[G]$, namely
 $$\alpha_{G,\K} = \sum_{g \in G} g(\alpha)g \in \K[G].$$
 Moreover, invertibility of $\osum{G}{\K}\in \K[G]$ is equivalent of having $\gcd (P(x),x^n-1) =1.$
 
 A close look at $M_G(x)$ tells us it is exactly the matrix of (left) multiplication by $$\osum{G}{\K} \in \K[G].$$  This gives an idea to modify Algorithm \ref{Alg:Naive}. Instead of writing $M_G(x)$ and test its  invertiblity, 
 we can write $\osum{G}{\K}$ and test if it is invertible in $\K[G]$. Although testing the invertibility of $\osum{G}{\K}$ might be efficient in
 comparison to computing the determinant of a matrix in $\K$, we prefer to do the computations over $\F$ rather than $\K$. The  following lemma
 comes handy to pass the computations from $\K$ to $\F$.


\begin{lemma}\label{Lem:Proj}
Assume $\alpha \in \K$. $M_G(\alpha) \in M_{n \times n}(\K)$ 
is invertible if and only if $$l(M_G(\alpha)) =  [l(g_ig_j(\alpha))]_{ij}  \in M_{n \times n}(\F)$$ is invertible,
 where $l$ is a generic projection of $\K$ to $\F$.
\end{lemma}

\begin{proof}
$(\Rightarrow)$ Since $\K = \F(\theta)$, for a fixed $\alpha$, any entry of $M_G(\alpha)$ can be written as 
\begin{equation}\label{Eq:PrimElm}
\sum_{k= 0}^{n-1} a_{ijk}\theta^k
\end{equation}
 and the corresponding entry in $l(M_G(\alpha))$ (for a random projection $l$)
 can be written $\sum_{k= 0}^{n-1} a_{ijk}l_k$ with $l_k\in \F$. If we replace this specific choice of $l_k$'s by 
 indeterminates $x_k$'s, we can see $\det(x(M_G(\alpha))$ is a polynomial in $\F[x_1, \ldots, x_n].$ Let 
 $$P(x_1, \ldots, x_n) = \det(x(M_G(\alpha)).$$ 
 Considering $P \in \K[x_1, \ldots , x_n]$, one can verify that 
 \begin{equation}\label{Eq:Det}
 det(M_G(\alpha))= P(1, \theta, \ldots, \theta^{n-1}) \neq 0
 \end{equation}
 since $M_G(\alpha)$ is invertible. Equation \eqref{Eq:Det} implies that $P(x_1, \ldots, x_n)$ is not identically zero over $\F$. Hence applying Theorem \ref{Thm:Zippel} with appropriate choice of parameters, we can see 
 the projection of $M_G(\alpha)$ is invertible for a generic choice of projection. 
 
 $(\Leftarrow)$  Note that elements of $G$ can act on 
 rows of $M_G(\alpha)$ entrywise and the action permutes the rows of $M_G(\alpha)$. Assume $\varphi : G \longrightarrow \mathfrak{S}_n$ is the group homomorphism 
 such that $g(M_i) = M_{\varphi(g)(i)}$ where $M_i$ is the $i$-th row of $M_G(\alpha)$.
 
 Assume $M_G(\alpha)$ is not invertible. Following the proof of \cite[Lemma 4]{Armin}, we show that there exists a non-zero $\textbf{u} \in \F^n$ in the kernel of $M_G(\alpha)$. 
 
 Since $M_G(\alpha)$ is singular, there exists a non-zero $\textbf{v} \in \K^n$  such that $M_G(\alpha)\textbf{v} = 0$ and $\textbf{v}$ has the minimum number of non-zero entries. Let $i \in  \lbrace 1, \ldots , n \rbrace$ such that $v_i \neq 0$. Define $\textbf{u} = \dfrac{1}{v_i}\textbf{v}$. It is clear  that $M_G(\alpha)\textbf{u} = 0$ which means $M_j \textbf{u} = 0 $ for $j \in \lbrace 1, \ldots, n \rbrace$. For $g \in G$
 \begin{equation}
  g(M_j \textbf{u}) = M_{\varphi(g)(j)} \textbf{u}= 0
 \end{equation}
 Since the above equation holds for any $j$ we conclude that $$M_G(\alpha)g(\textbf{u})= 0$$ hence
 $g(\textbf{u})-\textbf{u}$ is in the kernel of $M_G(\alpha)$. On the other hand since the $i$-th entry 
 of $\textbf{u}$ is one, the $i$-th entry of $g(\textbf{u}) -\textbf{u}$ is zero. Thus the minimality assumption
 on $\textbf{v}$ shows that $g(\textbf{u}) -\textbf{u} = 0$ and equivalently $g(\textbf{u})=\textbf{u}$. This 
 means $\textbf{u} \in \F^n$.
 
 
 Now we show that $l(M_G(\alpha))$ is not invertible for all
 choices of $l$. By Equation \eqref{Eq:PrimElm} we can write 
 $$M_G(\alpha) = \sum_{j = 1}^n M^{(j)} \theta^j$$ 
 where $M^{j} \in M_{n \times n}(\F)$. 
 
 Now $M_G(\alpha) \textbf{u} =0$ yields $M^{(j)}\textbf{u} = 0$ for $j \in \lbrace 1, \ldots , n \rbrace$. Hence
 $$\sum_{j = 1}^n M^{(j)} l_j \textbf{u} = 0$$ for any choice of $l_j$'s in $\F$. So $l(M_G(\alpha))$ is not invertible for any choice of $l$.
\end{proof} 
Lemma \ref{Lem:Proj} enables us to test invertibility of a random projection of $l(\alpha_{G,\K}) $ i.e. $\sum_{g \in G}
 l(g(\alpha))g \in \F[G]$. Although we can avoid writing $M_G(\alpha)$, we still need to compute $l(\alpha_{G,\K})$ which
 we call it the orbit sum projection problem.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "NormalBasisCharZero"
%%% End:
