\section{Computing projections of the orbit sum}
\label{sec:osum}

In this section we present algorithms to compute $s_{\alpha,\ell}$,
when $G$ is either abelian or metacyclic. We start by sketching our
ideas in simplest case, cyclic groups.  We will see that they follow
closely ideas used in \cite{KalSho98} over finite fields.

Suppose $G = \langle g \rangle$, so that given $\alpha$ in $\K$ and
$\ell: \K \to \F$, our goal is to compute
\begin{equation}
  \label{eq:cycproj}
  \ell(g^i(\alpha)), ~~\mbox{for}~ 0\leq i\leq n-1.
\end{equation}
\citeN{KalSho98} call this the \emph{automorphism projection problem} and
gave an algorithm to solve it in subquadratic time, when $g$ is the
$q$-power Frobenius $\mathbb{F}_{q^n} \to \mathbb{F}_{q^n}$.  The key idea in their
algorithm is to use the baby-steps/giant-steps technique: for a suitable
parameter $t$, the values in \eqref{eq:cycproj} can be rewritten as
\[
  (\ell \circ g^{tj})(g^i(\alpha)), ~~\mbox{for}~ 0 \leq j < m:=\lceil n/t
  \rceil ~\mbox{and}~ 0 \leq i <t.
\]
First, we compute all $G_i:=g^i(\alpha)$ for $0 \leq i <t$.  Then we compute
all $L_j:=\ell \circ g^{tj}$ for $0 \leq j <m$, where the $L_j$'s are
themselves linear mappings $\K \to \F$.  Finally, a matrix product yields
all values $L_j(G_i)$.

The original algorithm of \citeN{KalSho98} relies on the properties of the
Frobenius mapping to achieve subquadratic runtime. In our case, we cannot
apply these results directly; instead, we have to revisit the proofs
of~\citeN{KalSho98}, Lemmata 3, 4 and~8, now considering rectangular matrix
multiplication.  Our exponents involve the constant $\omega(4/3)$, for
which we have the upper bound $\omega(4/3) < 2.654$: this follows from the
upper bounds on $\omega(1.3)$ and $\omega(1.4)$ given by~\citeN{LeGall}, and
the fact that $k \mapsto \omega(k)$ is convex~\cite{LoRo83}. In particular,
$3/4 \cdot \omega(4/3) < 1.99$. Note also the inequality
$\omega(k) \ge 1+k$ for $k\ge 1$, since $\omega(k)$ describes products with
input and output size $O(n^{1+k})$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Multiple automorphim evaluation and applications}

The key to the algorithms below is the remark following
Assumption~\ref{assum}, which reduces automorphism evaluation to
composition of polynomials.  Over finite fields, this idea goes back
to~\citeN{GaSh92}, where it was credited to Kaltofen.

For instance, given $g \in G$ (by means of $\gamma:=g(\bar x)$), we can
deduce $g^2 \in G$ (again, by means of its image at $\bar x$) as
$\gamma(\gamma)$; this can be done in $\tilde{O}(n^{(\omega+1)/2})$
operations in $\F$ using Brent and Kung's modular composition
algorithm~\cite{BrKu78}. The algorithms below describe similar operations 
along these lines, involving several simultaneous evaluations.

\begin{lemma}\label{lem:modcom}
  Given $\alpha_1,\dots,\alpha_s$ in $\K$ and $g$ in $G =
  \mathrm{Gal}(\K/\F)$, with $s = O(\sqrt{n})$, we can compute
  $g(\alpha_1),\dots,g(\alpha_s)$ with $\tilde
  O(n^{(3/4)\cdot\omega(4/3)})$ operations in $\F$.
\end{lemma}
\begin{proof}
(Compare \cite[Lemma~3]{KalSho98}.) As noted above, for $i\le s$,
  $g(\alpha_i) = \alpha_i(\gamma)$, with $\gamma := g(\bar x) \in \K$.
  Let $t := \lceil n^{3/4} \rceil$, $m:=\lceil n/t\rceil$, and rewrite $\alpha_1 , \ldots , \alpha_s$ as 
$$\alpha_i = \sum_{0 \leq j < m} a_{i,j}\bar x^{tj},$$ where the
  $a_{i,j}$'s are polynomials of degree less than $t$. The next step
  is to compute $\gamma_i := \gamma^i$, for $i = 0 , \ldots , t$;
  there are $t$ products in $\K$ to do, so this amounts to
  $\tilde{O}(n^{7/4})$ operations in $\F$.

  Having $\gamma_i$'s in hand, one can form the matrix
  $\boldsymbol{\Gamma} := \left[ \Gamma_0 ~ \cdots ~ \Gamma_{t-1}
    \right]^T$, where each column $\Gamma_i$ is the coefficient vector
  of $\gamma_i$ (with entries in $\F$); this matrix has $t \in
  O(n^{3/4})$ rows and $n$ columns. We also form
  $$\mat A := \left[{A}_{1,0} \cdots {A}_{1,m-1} \cdots
    {A}_{s,0} \cdots {A}_{s,m-1}\right]^T,$$ where
  ${A}_{i,j}$ is the coefficient vector of $a_{i,j}$. This matrix 
  has $s m \in O(n^{3/4})$ rows and $t \in O(n^{3/4})$ columns.

  Compute $\mat B:=\mat A\, \boldsymbol{\Gamma}$; as per our
  definition of exponents $\omega(\ .\ )$, this can be done in
  $O(n^{3/4 \omega(4/3)})$ operations in $\F$, and the rows of this matrix
  give all $a_{i,j}(\gamma)$.  The last step to get all
  $\alpha_i(\gamma)$ is to write them as $\alpha_i(\gamma) = \sum_{0
    \leq j < m} a_{i,j}(\gamma) \Gamma_t^{j}.$ Using Horner's scheme,
  this takes $O(sm)$ operations in $\K$, which is $\tilde{O}(n^{7/4})$
  operations in $\F$. Since we pointed out that $\omega(3/4) \ge 7/4$,
  the leading exponent in all costs seen so far is
  ${3}/{4}\omega({4}/{3})$.
\end{proof}

\begin{lemma}\label{lem:selfcomp}
Given $\alpha$ in $\K$, $g_1, \ldots , g_{r}$ in $G =
\mathrm{Gal}(\K/\F)$ and positive integers $(s_1, \ldots s_r)$ such
that $\prod_{i = 1}^r s_i = O(\sqrt{n})$ and $r \in O(\log(n))$, all
  $$g_1^{i_1}\cdots g_r^{i_r}(\alpha) ,\quad \text{~for~} 0 \leq i_j
\leq s_j,\ 1 \leq j \leq r$$ can be computed in $\osumcosttilde$
operations in $\F$.
\end{lemma}
\begin{proof}
(Compare \cite[Lemma~4]{KalSho98}.) For $m=1,\dots,r$, suppose we have computed 
  $$G_{i_1,\dots,i_m}:=g_m^{i_m}\cdots g_1^{i_1}(\alpha)$$ for $0 \leq
  i_j \leq s_j$ if $1 \leq j < m$, and $0 \leq i_m < k_m,$ as well as
  the automorphism $\eta:={g_m}^{k_m}$ (by means of its value at $\bar
  x$, as per our convention).
  
 Then, we can get $G_{i_1,\dots,i_m}$ for $0 \leq i_j \leq s_j$ if $1
 \leq j < m$, and $0 \leq i_m < 2k_m$, by computing
 $\eta(G_{i_1,\dots,i_m})$, for all indices $i_1,\dots,i_m$ available
 to us, that is, $0 \leq i_j \leq s_j$ if $1 \leq j < m$, and $0 \leq
 i_m < k_m$. This can be carried out using $\osumcosttilde$ operations
 in $\F$ by applying Lemma \ref{lem:modcom}. Prior to entering the
 next iteration, we also compute $\eta^2$ by means of one modular
 composition, whose cost is negligible. 

 Using the above doubling method for $g_m$, we have to do $O(\log
 s_m)$ steps, for a total cost of $\osumcosttilde$ operations in $\F$.  We
 repeat this procedure for $m=1,\dots,r$; since $r$ is in $O(\log(n))$,
 the cost remains $\osumcosttilde$.
\end{proof}

We now present dual versions of the previous two lemmas (our
reference~\cite{KalSho98} also had such a discussion). Seen as an
$\F$-linear map, the operator $g:\alpha \mapsto g(\alpha)$ admits a
transpose, which maps an $\F$-linear form $\ell:\K\to\F$ to the
$\F$-linear form $\ell \circ g: \alpha \mapsto \ell(g(\alpha))$.  The
{\em transposition principle}~\cite{KaKiBs88,CaKaYa89} implies that if
a linear map $\F^N \to \F^M$ can be computed in time $T$, its
transpose can be computed in time $T+O(N+M)$. In particular, given $s$
linear forms $\ell_1,\dots,\ell_s$ and $g$ in $G$, transposing
Lemma~\ref{lem:modcom} shows that we can compute $\ell_1 \circ
g,\dots,\ell_s \circ g$ in time $\osumcosttilde$. The following lemma
sketches the construction.

\begin{lemma}\label{lem:modcomT}
  Given $\F$-linear forms $\ell_1,\dots,\ell_s:\K\to \F$ and $g$ in $G =
  \mathrm{Gal}(\K/\F)$, with $s = O(\sqrt{n})$, we can compute
  $\ell_1\circ g,\dots,\ell_s \circ g$ in time $\tilde
  O(n^{{3}/{4}\omega({4}/{3})})$.
\end{lemma}
\begin{proof}
  Given $\ell_i$ by its values on the power basis $1,\bar x,\dots,\bar
  x^{n-1}$, $\ell_i \circ g$ is represented by its values at
  $1,\gamma,\dots,\gamma^{n-1}$, with $\gamma := g(\bar x)$. 

  Let then $t,m$ and $\gamma_0,\dots,\gamma_t$ be as in the proof of
  Lemma~\ref{lem:modcom}. Next, compute the ``giant steps''
  $\gamma_t^j = \gamma^{tj}$, $j=0,\dots,m-1$ and for $i=1,\dots,s$
  and $j=0,\dots,m-1$, deduce the linear forms $L_{i,j}$ defined by
  $L_{i,j}(\alpha) := \ell_i(\gamma^{tj}\alpha)$ for all $\alpha$ in
  $\K$. Each of them can be obtained by a {\em transposed
    multiplication} in time $\tilde{O}(n)$~\cite[Section~4.1]{Shoup},
  so that the total cost thus far is $\tilde{O}(n^{7/4})$.

  Finally, multiply the $(sm \times
  n)$ matrix with entries the coefficients of all $L_{i,j}$ (as rows)
  by the $(n \times t)$ matrix with entries the coefficients of
  $\gamma_0,\dots,\gamma_{t-1}$ (as columns) to obtain all values
  $\ell_i(\gamma^j)$, for $i=1,\dots,s$ an $j=0,\dots,n-1$.
  This takes $O(n^{{3}/{4}\omega({4}/{3})})$ operations in~$\F$.
\end{proof}

From this, we deduce the transposed version of Lemma~\ref{lem:selfcomp},
whose proof follows the same pattern.
\begin{lemma}\label{lem:transmodcomp}
Given $\ell:\K\to F$, $g_1, \ldots , g_{r}$ in $G =
\mathrm{Gal}(\K/\F)$ and positive integers $(s_1, \ldots s_r)$ such
that $\prod_{i = 1}^r s_i = O(\sqrt{n})$ and $r \in O(\log(n))$, all
linear maps
  $$\ell \circ g_1^{i_1}\cdots g_r^{i_r} ,\quad \text{~for~} 0 \leq i_j
\leq s_j,\ 1 \leq j \leq r$$ can be computed in $\osumcosttilde$
operations in $\F$.
\end{lemma} 
\begin{proof}
  We proceed as in Lemma~\ref{lem:selfcomp}. For $m=1,\dots,r$,
  assumie we know
  $L_{i_1,\dots,i_m}:=\ell \circ (g_1^{i_1}\cdots g_m^{i_m}),$ for
  $0 \leq i_j \leq s_j$ if $1 \leq j < m$, and $0 \leq i_m < k_m.$
  Using the previous lemma, we compute all $L_{i_1,\dots,i_m} \circ
  {g_m}^{k_m},$ which gives us $L_{i_1,\dots,i_m}$ for indices $0 \le
  i_m < 2k_m$. The cost analysis is as in Lemma~\ref{lem:selfcomp}.
\end{proof}

%% At this point we have enough tools to see how the computation is
%% done in the cyclic case. Moreover, we can use the above lemmas to
%% give an algorithm for a more general case, namely the abelian
%% case. With a little bit more work we can state an algorithm which
%% solves the automorphism projection problem when $G = \lbrace a^ib^j
%% \rbrace$ where $m \leq n$. As an specific case this solves the
%% problem for metacyclic groups.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Abelian Groups}\label{ssec:proj_abelian}

The first main result in this section is the following proposition.
Assume $G$ is an abelian group presented as 
$$ \langle g_1, \ldots , g_r: g_{1}^{e_1} = \cdots = g_{r}^{e_r} = 1
\rangle$$ where $ e_i \in \mathbb{N}$ is the order of $g_i$ and $n =
e_1 \cdots e_r$; without loss of generality, we assume $e_i \ge 2$ for
all $i$, so that $r$ is in $O(\log(n))$. 

\begin{proposition}
  With notation as above, for $\alpha$ in $\K$ and $\ell:\K\to\F$, 
  $s_{\alpha,\ell} \in \F[G]$ is computable using  $\osumcosttilde$
  operations in $\F$.
\end{proposition}
\begin{proof}
Our goal is to compute
\begin{equation}\label{eq:abelian}
  \ell (g_1^{i_1},  \ldots, g_r^{i_r}(\alpha)), \, 1 \leq j \leq r, 0 \leq i_j \leq e_j,
\end{equation}
where $\ell$ is an $\F$-linear projection $\K\to \F$.  For $ 1\leq i
\leq r$, define $s_i:=\lceil\sqrt{e_i \rceil}$. As we sketched in the
cyclic case, the elements in \eqref{eq:abelian} can be expressed as
$L_{j_1,\cdots, j_r} (G_{i_1,\dots,i_r})$, 
for $1\leq m \leq r, 0\leq i_m < s_m, 0 \leq j_m < s_m$.
Here, $L_{j_1\cdots j_r} :=\ell \circ (g_1^{s_1j_1} \cdots
g_r^{s_rj_s})$ are linear projections presented as row vectors and
$G_{i_1,\dots,i_r}:=g_1^{i_1} \cdots g_r^{i_r}(\alpha)$ are field
elements presented as column vectors. All elements in
\eqref{eq:abelian} can be computed in 3 steps, the sum of whose 
costs proves the proposition.

\smallskip\noindent \textbf{Step 1.} Apply Lemma \ref{lem:selfcomp} to get 
$$G_{i_1,\dots,i_r}=g_1^{i_1} \cdots g_r^{i_r}(\alpha), \,\, 1\leq m \leq r, 0\leq i_m < s_m,$$
with cost $\osumcosttilde$

\smallskip\noindent\textbf{Step 2.} Use Lemma \ref{lem:transmodcomp} to compute 
$$L_{j_1,\cdots,j_r} = \ell \circ (g_1^{s_1j_1} \cdots
g_r^{s_rj_s}), \,\, 1\leq m \leq r, 0 \leq j_m < s_m,$$
with cost $\osumcosttilde$

\smallskip\noindent\textbf{Step 3.} Multiply the matrix with rows the
coefficients of all $L_{j_1,\cdots,j_r}$ by the matrix with columns
the coefficients of all $G_{i_1,\dots,i_r}$; this yields all required
values, as pointed out above. We can compute this  product in
$O(n^{1/2\omega(2)})$ operations in $\F$, which is $\osumcost$.
\end{proof}

\subsection{Metacyclic Groups}

A Group $G$ is called metacyclic if it has a normal cyclic subgroup, $H$, such that $G/H$ is cyclic. It is known that any group
with a square free order, is metacyclic and elements of a metacyclic group can be presented as 
\begin{equation}\label{eq:metacyclic}
\langle \sigma,\tau: \sigma^n = 1, \tau^{-1}\sigma \tau = \sigma^r, \tau ^m = \sigma^s \rangle
\end{equation}
where $m,n,r,s \in \mathbb{N}, r,s \leq n,$ and $r^m = 1 \mod n , rs = s \mod n$. Moreover we know that all element of a metacyclic
 group can be presented by $$\sigma^i \tau^j, \,\,\, 0\leq i \leq m-1, 0\leq j \leq n-1.$$ 
for more details on metacyclic groups see \cite[P.88, Proposition 1]{Johnson}, \cite[P.334]{Curtis}. for constructing some 
Metacyclic extensions see \cite{Kida}.

. Dihedral group 
$$D_{2n} = \langle \sigma,\tau: \sigma^n =\tau^2 = 1, \sigma \tau = \tau \sigma^{-1} \rangle, $$
is an example of metacyclic groups. another well-known metacyclic group is generalized quaternion
 group which can be presented as
 $$Q_n = \langle \sigma,\tau: \sigma^n =\tau^2, \tau \sigma \tau^{-1} = \sigma^{-1} \rangle.$$
 We know that elements of $Q_n$ are of the form 
 $$\sigma^i\tau^j, 0 \leq i \leq 2n-1 , 0\leq j \leq 1.$$
 
Assume $G = \mathrm{Gal(K/F})$ is a group presentable as
$$G = \lbrace \sigma^i \tau^j: 0\leq i < n, 0 \leq j < m, m\leq n \rbrace,$$
and $\alpha\in K$. The goal is to compute 
$L(\sigma^i\tau^j (\alpha), \,\, 0\leq i < n, 0 \leq j <m.$
This can be done in three steps.

\textbf{step 1.} apply Lemma \ref{lem:selfcomp} to compute 
$$s_{ij} = \sigma^i\tau^j(\alpha), 0 \leq j < m, 0\leq i < \lceil \sqrt{n}/\sqrt{m} \rceil$$
note that $\lceil \sqrt{n}/\sqrt{m} \rceil m \leq \lceil \sqrt{mn} \rceil$.

\textbf{step 2.} compute $$T_j = L \circ \sigma^{j\sqrt{mn}}, \,\, 0\leq j < \lceil \sqrt{mn}\rceil$$
using Lemma	\ref{lem:transmodcomp}.

\textbf{step 3.} at this point we want to compute 
$$L(\sigma^i\tau^j(\alpha)) = T_k\cdot(\sigma^i(\alpha_j)).$$
This can be carried out with a rectangular matrix multiplication
$$
\left[ \begin{array}{c}
T_0\\
\hline
T_1\\
\hline
\vdots\\
\hline
T_{\lceil \sqrt{mn} \rceil-1}
\end{array} 
\right]
\cdot
\left[\begin{array}{l}
s_{00} \\
\hline
 \vdots \\
 \hline
s_{0m} \\
 \hline
\vdots \\
\hline
s_{\lceil \sqrt{n}/\sqrt{m} \rceil 0} \\
\hline
\vdots \\
\hline
s_{\lceil \sqrt{n}/\sqrt{m} \rceil m}
\end{array}
\right]^t
$$
which is a $\langle \sqrt{mn},n,\sqrt{mn}\rangle$ multiplication. 

We note the above algorithm works for a class of groups which includes metacyclic case. Since if $G$ is metacyclic, 
$H = \langle \sigma \rangle \unlhd G$ and $G/H = \langle \tau H \rangle$, then both $\tau \sigma \tau^{-1}$ and 
$\tau^{-1} \sigma \tau$ belong to $H$. This implies elements of $G$ can be presented either as $\sigma^i\tau^j$
or $\tau^j\sigma^i$. Thus without loss of generality we can assume the $\textrm{Ord}(\tau) \leq \textrm{Ord}(\sigma)$.

Similar to the abelian case the final output of the above algorithm is a $\lceil \sqrt{n} \rceil \times \lceil \sqrt{n} \rceil $
matrix and $l(\osum{G}{K})$ can be calculated in the same way. Hence we have proved the following proposition.
 
\begin{proposition}
Suppose Assumption \ref{assum} holds and $G$ is a metacyclic group. $l(\osum{K}{G}) \in F[G]$ is computable using $\thecost$ 
operations in $F$.
\end{proposition}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "NormalBasisCharZero"
%%% End:
