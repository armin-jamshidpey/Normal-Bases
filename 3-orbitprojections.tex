\section{Computing projections of the orbit sum}\label{sec:osum}

So far we have reduced the problem of invertiblity of $M_G(\alpha)$ to $l(\osum{G}{K}) \in F[G]$ for a generic
projection $l$. In order to compute $l(\osum{G}{K})$ we need $l(g(\alpha)) \in F$ for $g \in G$. In this section we present 
algorithms to compute the mentioned terms which lead to compute $\osum{G}{K}$ in case that $G$ is either abelian or metacyclic. 
The best way to start is to take a look at the simplest case which is the cyclic one. 

Suppose $G = \langle g \rangle$
where $g$ is the Frobenius map. In \cite{Kaltofen} the problem of
computing 
\begin{equation}\label{eq:cycproj}
l(g^i(\alpha)), 0 \leq i \leq n-1,
\end{equation}
is called automorphism projection problem and an algorithm to solve 
the problem is introduced. Here we briefly explain the idea of the mentioned algorithm and later on we introduce a
generalized version of it which works for any finite abelian group.

With $l,g,G$ as above, $\alpha \in K$ and $Q$ as the corresponding matrix to Frobenius map, the values in \eqref{eq:cycproj} is rewritten as
$$(lQ^{tj})\cdot(Q^i\alpha), \,\, 0 \leq j <m, 0 \leq i <t$$
 for a chosen value $t$, can be computed in three steps. The first step is to compute $Q^i\alpha$ for $0 \leq i <t$. Afterwards
 compute $lQ^{tj}$ for $0 \leq j <m$ by doing $m-1$ transposed modular composition which in turn uses an algorithm given
 in \cite{Shoup}. At the end the terms in \eqref{eq:cycproj} can be computed by a matrix multiplication.
 
the details of above computations in \cite{Kaltofen} is presented useing 3 lemmas. At this point we provide the following 
lemmas which are variants of \cite[Lemma 3, Lemma 4 $\&$ Lemma 8]{Kaltofen}, with a slight modification in the proofs.

\begin{lemma}\cite{Kaltofen}\label{lem:modcom}
Assume $K$ is a field, $f\in K[x]$ is of degree $n$ and $s = \lceil\sqrt{n}\rceil$. Given $g_1, \ldots , g_{s}$ and 
$h \in K[x]$ of degree less than $n$, $$g_1(h), \ldots g_{s}(h) \mod f$$ can be computed in
$O(n^{\frac{3}{4}\omega(\frac{4}{3})})$ where $\omega(\frac{4}{3})$ is the exponent of rectangular matrix 
multiplication as introduced in \cite{LeGall}. 
\end{lemma}

\begin{proof}
Let $t = \lceil n^{3/4} \rceil$ and rewrite $g_1 , \ldots , g_s$ as 
$$g_i = \sum_{0 \leq j < n/t} g_{ij}x^{tj}.$$
Now $g_{ij}$'s are polynomials of degree less than $t$. The next step is to compute $H_i = h^i \mod f$ for $i = 0 , \ldots , t$.
Having $H_i$'s in hand one can form the matrix $H = \left[ H_1 \vert \cdots \vert H_t \right]^T$ where each column is the vector of 
the element $H_i$ (with coefficients in $K$) so the matrix $H$ is of size $t \times n$. We form 
$$A = \left[\bar{g}_{10}\vert \cdots \vert \bar{g}_{1(n/t-1)}\vert \cdots \vert \bar{g}_{s0}\vert \cdots \vert \bar{g}_{s(n/t-1)}\right]^T,$$
where $\bar{g}_{ij}$ is the  vector of $g_{ij}$. In order to compute $g_{ij}(h)$ one can compute $A \cdot H$. Using 
results from \cite{LeGall}, this can be done in $O(n^{3/4 \omega(4/3)})$. The last step to get $g_i(h)$, is to substitute $H_t$ 
for $x^t$ and performing a Horner evaluation scheme. The dominant term in the cost of this calculation, is the cost of computing $AH$ which can be carried out using $O(n^{3/4 \omega(4/3)})$ operations in $K$.
\end{proof}

\begin{lemma}\cite{Kaltofen}\label{lem:selfcomp}
Under Assumption \ref{assum}, for $\lbrace s_1, \ldots s_r \rbrace \subset \mathbb{N}$
such that $\prod_{i = 1}^r s_i = O(\sqrt{n})$ and $g_1, \ldots , g_{r} \in G = \mathrm{Gal}(K/F)$ 
$$g_1^{i_1}\cdots g_r^{i_r}(\alpha) , 1 \leq j \leq r, 
0 \leq i_j \leq s_j$$ can be 
computed in $\osumcosttilde$ where $\omega(\frac{4}{3})$ is the exponent of rectangular matrix 
multiplication as introduced in \cite{LeGall}. 
\end{lemma}

\begin{proof}
Suppose $1 \leq m \leq r$ is fixed and we have computed $$g_m^{i_m}\cdots g_1^{i_1}(\alpha) ,\,  1 \leq j < m, \, 
0 \leq i_j \leq s_j, \, 0 \leq i_m \leq k_m.$$
Then we can get $$g_m^{i_m}\cdots g_1^{i_1}(\alpha) ,\, 1 \leq j < m, \, 0 \leq i_j \leq s_j,\, 0 \leq i_m \leq 2k_m,$$
by computing 
$$g_m^{k_m}(g_m^{i_m}\cdots g_1^{i_1}(\alpha)),\, 1 \leq j \leq r,\, 0 \leq i_j \leq s_j,\, 0 \leq i_m \leq k_m$$
which can be carried out using $\osumcost$ operations in $F$ by applying Lemma \ref{lem:modcom} and using Remark \ref{rmk:comute}.
Using above doubling method for $g_i$, we have to do $O(\log s_i)$ iterations with $\osumcost$ operations in $F$. Hence the total cost of this 
computation is $\osumcosttilde$

Note that for each $g_i$ we have to compute $g_i^{2^j}$ for $0 \leq j \leq \log(s_i)$ but this is just a one time computation for each $g_i$
which does not change the total cost.
\end{proof}

\begin{lemma}\label{lem:transmodcomp}
Under Assumption \ref{assum}, for $\lbrace s_1, \ldots, s_r \rbrace \subset \mathbb{N}$
such that $\prod_{i = 1}^r s_i = O(\sqrt{n})$
 and $L: K\rightarrow F$ is a linear projection. The linear maps
$$L \circ g_1^{i_1} \cdots g_r^{i_r}, \,\, 1\leq j \leq r, 0 \leq i_j < s_j, $$ can be computed using $\osumcosttilde$ operations in $F$. 
\end{lemma} 

\begin{proof}
Let $T_{i_1\cdots i_r} = L \circ g_1^{i_1}\cdots g_r^{i_r}$. Here we use a doubling method. Assume $1 \leq m \leq r$ is fixed and we have have access to 
$$T_{i_1\cdots i_m}, \, \mathrm{for}\,\, 1\leq j < m, 0 \leq i_j \leq s_j, 0 \leq i_m \leq k_m.$$
Then we can compute 
$$T_{i_1\cdots i_m}, \, , 1 \leq j < m, 0 \leq i_j \leq s_j, 0 \leq i_m \leq 2k_m,$$
in the following way. We compute 
$T_{i_1 \cdots i_m} \circ g_m^{k_m}, \,\, 1\leq j \leq m, 0 \leq i_j \leq s_j.$
 Since a linear projection is determined by its action on a basis, such as 
$\lbrace\bar{x}^i: 0\leq i \leq n-1 \rbrace$, the corresponding row vector to $T_{i_1 \cdots i_m} \circ g_m^{k_m}$ is 
\begin{equation}\label{eq:projvec}
\begin{bmatrix} T_{i_1 \cdots i_m}(u_{m,k_m}^0) & \cdots & T_{i_1 \cdots i_m}(u_{m,k_m}^{n-1}) \end{bmatrix}
\end{equation}
where $u_{m,k_m} = g_m^{k_m}(\bar{x})$. In order to compute the above row vector for a fixed index $i_1 \cdots i_m$, let $s = \lceil n^{1/4} \rceil$, compute
$$\overline{T_{i_1 \cdots i_m}} = \left[\begin{array}{c|c|c}
u_{m,k_m}^0\cdot T_{i_1 \cdots i_m} & \cdots & u_{m,k_m}^{s-1}\cdot T_{i_1 \cdots i_m}
\end{array} \right]$$
and multiply it by 
$$ U = \left[
\begin{array}{c}
u_{m,k_m}^0\\
\hline
u_{m,k_m}^{s}\\
\hline
u_{m,k_m}^{2s}\\
\hline
\vdots\\
\hline
u_{m,k_m}^{(\lceil n^{3/4} \rceil-1)s}
\end{array} \right].$$
Note that the term $u_{m,k_m}^i \cdot T_{i_1 \cdots i_m}$, is the so called transposed modular multiplication and one can apply the algorithm introduced in \cite{Shoup} to compute it. It is clear that $U$ is of size 
$\lceil n^{3/4} \rceil \times n$ and $\overline{T_{i_1 \cdots i_m}}$ is an $n \times n^{1/4}$. Finally the vectors in \eqref{eq:projvec}
is given by
$$
U \cdot \left[\begin{array}{c|c|c|c|c}
\overline{T_{0 \cdots 0}} & \cdots &\overline{T_{i_1 \cdots i_{m-1}0}} & \cdots & \overline{T_{k_1 \cdots k_m}}
\end{array}\right].
$$
This completes the doubling method.

Note that in the last step of above doubling method for a fixed index $t$ we have $k_t = s_t/2$. Hence for $g_t$ the above computation can be done 
using $O(\log s_t)$ times the cost of the matrix multiplication which is $\osumcost$. Since we should repeat the above process for each $g_t$ the total cost is
$\osumcosttilde$ 
\end{proof}


At this point we have enough tools to see how the computation is done in the cyclic case. Moreover, we can use the above lemmas
to give an algorithm for a more general case, namely the abelian case. With a little bit more work we can state an algorithm 
which solves the automorphism projection problem when $G = \lbrace a^ib^j \rbrace$ where $m \leq n$. As an specific case this
solves the problem for metacyclic groups.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Abelian Groups}\label{ssec:proj_abelian}

Assume $G$ is an abelian group presented as 
$$ \langle g_1, \ldots , g_r: g_{1}^{e_1} = \cdots = g_{r}^{e_r} = 1 \rangle$$
 where $ e_i \in \mathbb{N}$
is the order of $g_i$ and $n = e_1 \cdots e_r$. Moreover, let $s_i = \lceil	\sqrt{e_i \rceil}$ for $ 1\leq i \leq r$.
 Our goal is to compute 
\begin{equation}\label{eq:abelian}
L (g_1^{i_1},  \ldots, g_r^{i_r}(\alpha)), \, 1 \leq j \leq r, 0 \leq i_j \leq e_j
\end{equation}
 where $L = \begin{bmatrix} l_1 & \cdots l_n \end{bmatrix}$ is a given projection from $K$ to $F$. 
similar to the cyclic case, the elements in \eqref{eq:abelian} can be presented as 
\begin{equation}
\begin{split}
(L \circ g_1^{s_1j_1} \cdots g_r^{s_rj_s})\cdot (g_1^{i_1} \cdots g_r^{i_r}(\alpha))\\ 1\leq m \leq r, 0\leq i_m < s_m, 0 \leq j_m < s_m
\end{split}
\end{equation}
note that $T_{j_1\cdots j_r} = L \circ g_1^{s_1j_1} \cdots g_r^{s_rj_s}$ are linear projections 
presented as row vectors and $g_1^{i_1} \cdots g_r^{i_r}(\alpha)$ are field elements presented as column vectors. All elements in \eqref{eq:abelian} can be computed in 3 steps.

\textbf{Step 1.} Apply Lemma \ref{lem:selfcomp} to get 
$$g_1^{i_1} \cdots g_r^{i_r}(\alpha), \,\, 1\leq m \leq r, 0\leq i_m < s_m,$$
with cost $\osumcosttilde$

\textbf{Step 2.} Use Lemma \ref{lem:transmodcomp} to compute 
$$T_{j_1\cdots j_r}, \,\, 1\leq m \leq r, 0 \leq j_m < s_m,$$
with cost $\osumcosttilde$

\textbf{Step 3.} The last step is to the following matrix multiplication

$$
\left[ \begin{array}{c}
T_{00\cdots 0}\\
\hline
T_{10\cdots 0}\\
\hline
\vdots\\
\hline
T_{s_1 \cdots s_r}
\end{array} \right]
\cdot
\left[\begin{array}{c}
g_1^{0}\cdots g_r^{0}(\alpha) \\
\hline
g_1^{1}\cdots g_r^{0}(\alpha) \\
\hline
\cdots \\
\hline
g_1^{s_1}\cdots g_r^{s_r}(\alpha)  
\end{array}\right]^t.
$$
Using results for rectangular matrix multiplication we can compute the above product in $O(n^{1/2\omega(2)})$ operations in $F$.
The above computation can be done in $\osumcosttilde$ operations in $F$ which produces a $\lceil \sqrt{n} \rceil \times \lceil
 \sqrt{n} \rceil$ matrix which contains all the projections. Concatenating the rows of the mentioned matrix forms a vector in
 $F[G]$ which is the corresponding vector to $\osum{G}{F}$ with respect to the basis $G$. This means we have proved the following
 proposition.

\begin{proposition}
Suppose Assumption \ref{assum} holds and $G$ is an abelian group. $l(\osum{K}{G}) \in F[G]$ is computable using $\thecost$ 
operations in $F$.
\end{proposition}

\subsection{Metacyclic Groups}

A Group $G$ is called metacyclic if it has a normal cyclic subgroup, $H$, such that $G/H$ is cyclic. It is known that any group
with a square free order, is metacyclic and elements of a metacyclic group can be presented as 
\begin{equation}\label{eq:metacyclic}
\langle \sigma,\tau: \sigma^n = 1, \tau^{-1}\sigma \tau = \sigma^r, \tau ^m = \sigma^s \rangle
\end{equation}
where $m,n,r,s \in \mathbb{N}, r,s \leq n,$ and $r^m = 1 \mod n , rs = s \mod n$. Moreover we know that all element of a metacyclic
 group can be presented by $$\sigma^i \tau^j, \,\,\, 0\leq i \leq m-1, 0\leq j \leq n-1.$$ 
for more details on metacyclic groups see \cite[P.88, Proposition 1]{Johnson}, \cite[P.334]{Curtis}. for constructing some 
Metacyclic extensions see \cite{Kida}.

. Dihedral group 
$$D_{2n} = \langle \sigma,\tau: \sigma^n =\tau^2 = 1, \sigma \tau = \tau \sigma^{-1} \rangle, $$
is an example of metacyclic groups. another well-known metacyclic group is generalized quaternion
 group which can be presented as
 $$Q_n = \langle \sigma,\tau: \sigma^n =\tau^2, \tau \sigma \tau^{-1} = \sigma^{-1} \rangle.$$
 We know that elements of $Q_n$ are of the form 
 $$\sigma^i\tau^j, 0 \leq i \leq 2n-1 , 0\leq j \leq 1.$$
 
Assume $G = \mathrm{Gal(K/F})$ is a group presentable as
$$G = \lbrace \sigma^i \tau^j: 0\leq i < n, 0 \leq j < m, m\leq n \rbrace,$$
and $\alpha\in K$. The goal is to compute 
$L(\sigma^i\tau^j (\alpha), \,\, 0\leq i < n, 0 \leq j <m.$
This can be done in three steps.

\textbf{step 1.} apply Lemma \ref{lem:selfcomp} to compute 
$$s_{ij} = \sigma^i\tau^j(\alpha), 0 \leq j < m, 0\leq i < \lceil \sqrt{n}/\sqrt{m} \rceil$$
note that $\lceil \sqrt{n}/\sqrt{m} \rceil m \leq \lceil \sqrt{mn} \rceil$.

\textbf{step 2.} compute $$T_j = L \circ \sigma^{j\sqrt{mn}}, \,\, 0\leq j < \lceil \sqrt{mn}\rceil$$
using Lemma	\ref{lem:transmodcomp}.

\textbf{step 3.} at this point we want to compute 
$$L(\sigma^i\tau^j(\alpha)) = T_k\cdot(\sigma^i(\alpha_j)).$$
This can be carried out with a rectangular matrix multiplication
$$
\left[ \begin{array}{c}
T_0\\
\hline
T_1\\
\hline
\vdots\\
\hline
T_{\lceil \sqrt{mn} \rceil-1}
\end{array} 
\right]
\cdot
\left[\begin{array}{l}
s_{00} \\
\hline
 \vdots \\
 \hline
s_{0m} \\
 \hline
\vdots \\
\hline
s_{\lceil \sqrt{n}/\sqrt{m} \rceil 0} \\
\hline
\vdots \\
\hline
s_{\lceil \sqrt{n}/\sqrt{m} \rceil m}
\end{array}
\right]^t
$$
which is a $\langle \sqrt{mn},n,\sqrt{mn}\rangle$ multiplication. 

We note the above algorithm works for a class of groups which includes metacyclic case. Since if $G$ is metacyclic, 
$H = \langle \sigma \rangle \unlhd G$ and $G/H = \langle \tau H \rangle$, then both $\tau \sigma \tau^{-1}$ and 
$\tau^{-1} \sigma \tau$ belong to $H$. This implies elements of $G$ can be presented either as $\sigma^i\tau^j$
or $\tau^j\sigma^i$. Thus without loss of generality we can assume the $\textrm{Ord}(\tau) \leq \textrm{Ord}(\sigma)$.

Similar to the abelian case the final output of the above algorithm is a $\lceil \sqrt{n} \rceil \times \lceil \sqrt{n} \rceil $
matrix and $l(\osum{G}{K})$ can be calculated in the same way. Hence we have proved the following proposition.
 
\begin{proposition}
Suppose Assumption \ref{assum} holds and $G$ is a metacyclic group. $l(\osum{K}{G}) \in F[G]$ is computable using $\thecost$ 
operations in $F$.
\end{proposition}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "NormalBasisCharZero"
%%% End:
