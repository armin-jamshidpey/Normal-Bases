\section{Preliminaries}
\label{sec:pre}

One of the well-known proofs of the existence of a normal element for a
finite Galois extension, as for example reported by \citet[Theorem 6.13.1]{Lang}, suggests a randomized
algorithm for finding such an element. Assume $\K/\F$ is a finite Galois
extension with Galois group $G = \lbrace g_1 , \ldots , g_n \rbrace$. If
$\alpha \in \K$ is a normal element, then
\begin{equation}
  \label{eq:fstrow}
  \sum_{j=1}^n 
  c_j g_j(\alpha)=0, \,\,\, c_j \in \F 
\end{equation} 
implies $c_1 =\dots=c_n = 0$. For each
$i \in \lbrace 1, \ldots , n\rbrace$, applying $g_i$ to equation
\eqref{eq:fstrow} yields
\begin{equation} \label{eq:otherrow} \sum_{j=1}^n c_j g_i g_j(\alpha)=0.
\end{equation}
Using \eqref{eq:fstrow} and \eqref{eq:otherrow}, one can form the linear
system $\mat{M}\boldsymbol{c} = \textbf{0}$,
with $\boldsymbol{c} = [ c_1~ \cdots~c_n]^T$ and
where, for $\alpha\in\K$,
\begin{equation}\label{eqdef:M}
  \mat M =
  \begin{bmatrix}
    g_1 g_1(\alpha) & g_1 g_2(\alpha) & \cdots & g_1 g_n(\alpha) \\
    g_2 g_1(\alpha) & g_2 g_2(\alpha) & \cdots & g_2 g_n(\alpha) \\
    \vdots		& \vdots	& \vdots & \vdots \\
    g_n g_1(\alpha) & g_n g_2(\alpha) & \cdots & g_n g_n(\alpha) \\
  \end{bmatrix} \in M_n(\K).
\end{equation}
Classical proofs then proceed to show that there exists $\alpha \in \K$
with $\det(\mat M)\neq 0$.
 
This approach can be used as the basis of a procedure to test if a
given $\alpha\in\K$ is normal, by computing all the entries of the
matrix $\mat M$ and using linear algebra to compute its determinant;
using fast matrix arithmetic this requires $O(n^\omega)$ operations in
$\K$, that is $\tilde{O}(n^{\omega+1})$ operations in $\F$. This is at
least cubic in $n$; the main contribution of this paper is to show how
to speed up this verification.
 
Before entering that discussion, we briefly comment on the probability
that $\alpha$ be a normal element: if we write $\alpha = a_0 + \cdots
+ a_{n-1} \xbar^{n-1}$, the determinant of $\mat M$ is a
(not identically zero) homogeneous polynomial of degree $n$ in
$(a_0,\dots,a_{n-1})$. If the $a_i$'s are chosen uniformly at random
in a finite set $X \subset \F$, the Lipton-DeMillo-Schwartz-Zippel lemma
implies that the probability that $\alpha$ be normal is at least
$1-n/|X|$.

If $G$ is cyclic generated by an element $g$, with $g_1 = {\rm id}$
and $g_{i+1} = g g_i$ for all $i$, \cite{GatGie90} avoid computing a
determinant by computing the GCD of $S_\alpha := \sum_{i = 1}^{n}
g_i(\alpha)x^{i-1}$ and $x^n-1$. In effect, this amounts to testing
whether $S_\alpha$ is invertible in the group ring $\K[G]$, which is
isomorphic to $\K[x]/\langle x^n-1\rangle$. This is a general fact:
for any $G$, matrix $\mat M$ above is the matrix of left
multiplication by the orbit sum
$$S_\alpha:= \sum_{i=1}^n g_i(\alpha)g_i \in \K[G],$$ where we index
rows by $g_1,\dots,g_n$ and columns by their inverses
$g_1^{-1},\dots,g_n^{-1}$. In terms of notation, for any field
$\mathsf L$ (typically, we will take either $\mathsf L = \F$ or
$\mathsf L = \K$), and $\beta$ in $\mathsf L[G]$, we will write $\mat
M_{\mathsf L}(\beta)$ for the left multiplication matrix by $\beta$ in
$\mathsf L[G]$, using the two bases shown above.  In other words, the
matrix $\mat M$ of~\eqref{eqdef:M} is $\mat M_\K(S_\alpha)$.

The previous discussion shows that $\alpha$ being normal is equivalent
to $S_\alpha$ being a unit in $\K[G]$. This point of view may make it
possible to avoid linear algebra of size $n$ over $\K$, but writing
$S_\alpha$ itself still involves $\Theta(n^2)$ elements in $\F$. The
following lemma is the main new ingredient in our algorithm: it gives
a randomized reduction to testing whether a suitable projection of
$S_\alpha$ in $\F[G]$ is a unit.


\begin{lemma}
  \label{Lem:Proj}
  For $\alpha \in \K$, $\mat M_\K(S_\alpha)$ is invertible if and only
  if $$\ell(\mat M_\K(S_\alpha)) := [\ell(g_ig_j(\alpha))]_{ij} \in M_n(\F)$$
  is invertible for a generic $\F$-linear projection $\ell: \K \to \F$.
\end{lemma}
\begin{proof}
  $(\Rightarrow)$ For a fixed $\alpha\in\K$, any entry of
  $\mat M_\K(S_\alpha)$ can be written as
  \begin{equation}\label{Eq:PrimElm}
    \sum_{k= 0}^{n-1} a_{ijk}\xbar^k,
  \end{equation}
  and for $\ell: \K \to \F$, the corresponding entry in $\ell(\mat
  M_\K(S_\alpha))$ can be written $\sum_{k= 0}^{n-1} a_{ijk}\ell_k$, with
  $\ell_k = \ell(\xbar^k)$. Replacing these $\ell_k$'s by
  indeterminates $L_k$'s, the determinant becomes a polynomial in $P
  \in \F[L_1, \ldots, L_n].$ Viewing $P$ in $\K[L_1, \ldots, L_n]$, we
  have $ P(1, \xbar, \ldots, \xbar^{n-1})$ $= \det(\mat M_\K(S_\alpha))$,
  which is non-zero by assumption. Hence, $P$ is not identically zero,
  and the conclusion follows.
  
  $(\Leftarrow)$ Assume $\mat M_\K(S_\alpha)$ is not invertible. Following the
  proof of \citet[Lemma 4]{Jam18}, we first show that there exists a
  non-zero $\boldsymbol{u} \in \F^n$ in the kernel of $\mat M_\K(S_\alpha)$.
  
  The elements of $G$ act on rows of $\mat M_\K(S_\alpha)$ entrywise and the
  action permutes the rows the matrix. Assume
  $\varphi : G \to \mathfrak{S}_n$ is the group homomorphism such that
  $g(\mat M_i) = \mat M_{\varphi(g)(i)}$ for all $i$, where $\mat M_i$ is
  the $i$-th row of $\mat M_\K(S_\alpha)$.
  
  Since $\mat M_\K(S_\alpha)$ is singular, there exists a non-zero
  $\boldsymbol{v} \in \K^n$ such that $\mat M_\K(S_\alpha)\boldsymbol{v} = 0$;
  we choose $\boldsymbol{v}$ having the minimum number of non-zero
  entries. Let $i \in \lbrace 1, \ldots , n \rbrace$ such that
  $v_i \neq 0$. Define $\boldsymbol{u} = 1/v_i\boldsymbol{v}$. Then,
  $\mat M_\K(S_\alpha)\boldsymbol{u} = 0,$ which means
  $\mat M_j \boldsymbol{u} = 0 $ for $j \in \lbrace 1, \ldots, n
  \rbrace$. For $g \in G$, we have
  $g(\mat M_j \boldsymbol{u}) = \mat M_{\varphi(g)(j)} g(\boldsymbol{u})=
  0.$ Since this holds for any $j$, we conclude that
  $\mat M_\K(S_\alpha)g(\boldsymbol{u})= 0$, hence
  $g(\boldsymbol{u})-\boldsymbol{u}$ is in the kernel of
  $\mat M_\K(S_\alpha)$. On the other hand since the $i$-th entry of
  $\boldsymbol{u}$ is one, the $i$-th entry of
  $g(\boldsymbol{u}) -\boldsymbol{u}$ is zero. Thus the minimality
  assumption on $\textbf{v}$ shows that
  $g(\boldsymbol{u}) -\boldsymbol{u} = 0$, equivalently
  $g(\boldsymbol{u})=\boldsymbol{u}$, and hence $\boldsymbol{u} \in \F^n$.
  
  Now we show that $\ell(\mat M_\K(S_\alpha))$ is not invertible for all
  choices of $\ell$. By Equation \eqref{Eq:PrimElm}, we can write
  $$\mat M_\K(S_\alpha) = \sum_{j = 0}^{n-1} \mat M^{(j)} \xbar^j, \quad 
  \mat M^{(j)} \in M_{n}(\F) \text{~for all $j$}.$$ 
  Since $\boldsymbol{u}$ has entries in $\F$,
  $\mat M_\K(S_\alpha) \boldsymbol{u} =0$ yields
  $\mat M^{(j)}\boldsymbol{u} = 0$ for
  $j \in \lbrace 1, \ldots , n \rbrace$. Hence,
$$\sum_{j = 0}^{n-1} \mat M^{(j)} \ell_j \boldsymbol{u} = 0$$ for any 
$\ell_j$'s in $\F$, and $\ell(\mat M_\K(S_\alpha))$ is not invertible for any~$\ell$.
\end{proof} 
Our algorithm can be sketched as follows: given $\alpha$ in $\K$,
choose a random $\ell: \K\to\F$, and let
\begin{equation}\label{def:s_alpha_ell}
s_{\alpha,\ell}:=\sum_{i=1}^n \ell(g_i(\alpha))g_i \in \F[G].
\end{equation}
Note that $\ell(\mat M_\K(S_\alpha))$ is equal to $\mat
M_\F(s_{\alpha,\ell})$, that is, the multiplication matrix by
$s_{\alpha,\ell}$ in $\F[G]$, where, as above, we index rows by
$g_1,\dots,g_n$ and columns by $g_1^{-1},\dots,g_n^{-1}$.  Then,
the previous lemma can be rephrased as follows:
\begin{lemma}
  \label{Lem:Proj-bis}
  For $\alpha \in \K$, $\alpha$ is normal if and only if
  $s_{\alpha,\ell}$ is invertible in $\F[G]$ for a generic
  $\F$-linear projection $\ell: \K \to \F$.
\end{lemma}
Thus, once $s_{\alpha,\ell}$ is known, we are left with testing
whether it is a unit in $\F[G]$. In the next two sections, we address
the respective questions of computing $s_{\alpha,\ell}$, and testing
its invertibility in $\F[G]$.
\begin{remark}\label{rmk:mc-epsilon}
The polynomial $P$ in the proof of Lemma \ref{Lem:Proj}, is a homogeneous 
polynomial of degree $n$ in $(L_1, \ldots , L_n)$. By Lipton-DeMillo-
Schwartz-Zippel lemma (if we choose $L_i$'s uniformly at random in any 
fixed finite subset $X \subset \F$) one can conclude that $P$ is zero with 
probability less than $n/|X|$ and this implies that the $\epsilon$ in Remark \ref{rmk:mc-prob}, can be equal to $n/|X|$.
\end{remark}





%%% Local Variables:
%%% mode: latex
%%% TeX-master: "NormalBasisCharZero"
%%% End:
